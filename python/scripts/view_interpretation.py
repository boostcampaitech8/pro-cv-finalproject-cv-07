"""
TFT Interpretation Data Viewer

interpretation.npz íŒŒì¼ì˜ ë‚´ìš©ì„ í™•ì¸í•˜ê³  ì‹œê°í™”í•˜ëŠ” ë„êµ¬

Usage:
    python view_interpretation.py --interp_file fold_0_interpretation.npz
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import argparse


def load_interpretation_file(file_path: str):
    """
    interpretation.npz íŒŒì¼ ë¡œë“œ
    
    Args:
        file_path: .npz íŒŒì¼ ê²½ë¡œ
    
    Returns:
        dict with variable_importance and attention_weights
    """
    if not Path(file_path).exists():
        raise FileNotFoundError(f"File not found: {file_path}")
    
    data = np.load(file_path, allow_pickle=True)
    
    print(f"\n{'='*60}")
    print(f"Interpretation File: {file_path}")
    print(f"{'='*60}")
    
    # íŒŒì¼ ë‚´ìš© í™•ì¸
    print(f"\nğŸ“¦ Contents:")
    for key in data.files:
        print(f"  - {key}")
    
    return data


def analyze_variable_importance(data: np.lib.npyio.NpzFile):
    """
    Variable importance ë¶„ì„
    
    Args:
        data: loaded .npz file
    """
    if 'variable_importance' not in data:
        print("\nâš ï¸  No variable_importance in this file")
        return None
    
    var_importance = data['variable_importance']
    
    print(f"\n{'='*60}")
    print("ğŸ“Š Variable Importance Analysis")
    print(f"{'='*60}")
    
    print(f"\nData structure:")
    print(f"  - Type: {type(var_importance)}")
    print(f"  - Shape: {len(var_importance)} epochs saved")
    
    if len(var_importance) > 0:
        # ë§ˆì§€ë§‰ epoch ë¶„ì„
        last_epoch = var_importance[-1]
        print(f"\nLast epoch data:")
        print(f"  - Shape: {last_epoch.shape}")
        print(f"    [num_samples={last_epoch.shape[0]}, " \
              f"seq_length={last_epoch.shape[1] if len(last_epoch.shape) > 1 else 'N/A'}, " \
              f"num_features={last_epoch.shape[2] if len(last_epoch.shape) > 2 else 'N/A'}]")
        
        # í‰ê·  ì¤‘ìš”ë„
        if len(last_epoch.shape) == 3:
            avg_importance = last_epoch.mean(axis=(0, 1))
            print(f"\nğŸ“ˆ Average importance across all samples & timesteps:")
            print(f"  Min: {avg_importance.min():.6f}")
            print(f"  Max: {avg_importance.max():.6f}")
            print(f"  Mean: {avg_importance.mean():.6f}")
            print(f"  Std: {avg_importance.std():.6f}")
            
            # Top 10 features
            top_indices = np.argsort(avg_importance)[-10:][::-1]
            print(f"\nğŸ† Top 10 Most Important Features (indices):")
            for i, idx in enumerate(top_indices, 1):
                print(f"  {i}. Feature {idx}: {avg_importance[idx]:.6f}")
        
        return var_importance
    else:
        print("\nâš ï¸  No data in variable_importance")
        return None


def analyze_attention_weights(data: np.lib.npyio.NpzFile):
    """
    Attention weights ë¶„ì„
    
    Args:
        data: loaded .npz file
    """
    if 'attention_weights' not in data:
        print("\nâš ï¸  No attention_weights in this file")
        return None
    
    attn_weights = data['attention_weights']
    
    print(f"\n{'='*60}")
    print("ğŸ” Attention Weights Analysis")
    print(f"{'='*60}")
    
    print(f"\nData structure:")
    print(f"  - Type: {type(attn_weights)}")
    print(f"  - Shape: {len(attn_weights)} epochs saved")
    
    if len(attn_weights) > 0:
        # ë§ˆì§€ë§‰ epoch ë¶„ì„
        last_epoch = attn_weights[-1]
        print(f"\nLast epoch data:")
        print(f"  - Shape: {last_epoch.shape}")
        if len(last_epoch.shape) == 4:
            print(f"    [num_samples={last_epoch.shape[0]}, " \
                  f"num_heads={last_epoch.shape[1]}, " \
                  f"seq_length={last_epoch.shape[2]}, " \
                  f"seq_length={last_epoch.shape[3]}]")
        
        # í‰ê·  attention
        if len(last_epoch.shape) == 4:
            avg_attention = last_epoch.mean(axis=(0, 1))  # [seq_length, seq_length]
            print(f"\nğŸ“ˆ Average attention (across samples & heads):")
            print(f"  Shape: {avg_attention.shape}")
            print(f"  Min: {avg_attention.min():.6f}")
            print(f"  Max: {avg_attention.max():.6f}")
            print(f"  Sum per row: {avg_attention.sum(axis=1).mean():.6f} (should be ~1.0)")
            
            # ê° timestepì˜ ì¤‘ìš”ë„
            temporal_importance = avg_attention.mean(axis=0)
            print(f"\nâ° Temporal Importance (average attention received):")
            for t in range(len(temporal_importance)):
                print(f"  t-{len(temporal_importance)-t-1}: {temporal_importance[t]:.6f}")
        
        return attn_weights
    else:
        print("\nâš ï¸  No data in attention_weights")
        return None


def visualize_attention_heatmap(
    attn_weights: np.ndarray,
    save_path: str = "attention_heatmap.png"
):
    """
    Attention weights heatmap ì‹œê°í™”
    
    Args:
        attn_weights: attention weights array (epochs saved)
        save_path: ì €ì¥ ê²½ë¡œ
    """
    if attn_weights is None or len(attn_weights) == 0:
        print("\nâš ï¸  No attention weights to visualize")
        return
    
    # ë§ˆì§€ë§‰ epoch ì‚¬ìš©
    last_epoch = attn_weights[-1]
    
    if len(last_epoch.shape) != 4:
        print(f"\nâš ï¸  Unexpected shape: {last_epoch.shape}")
        return
    
    # í‰ê·  attention
    avg_attention = last_epoch.mean(axis=(0, 1))
    seq_length = avg_attention.shape[0]
    
    # ì‹œê°í™”
    plt.figure(figsize=(10, 8))
    sns.heatmap(
        avg_attention,
        xticklabels=[f't-{seq_length-i-1}' for i in range(seq_length)],
        yticklabels=[f't-{seq_length-i-1}' for i in range(seq_length)],
        cmap='Blues',
        cbar_kws={'label': 'Attention Weight'},
        annot=False,
        fmt='.3f'
    )
    plt.xlabel('Key Position')
    plt.ylabel('Query Position')
    plt.title('Average Attention Weights\n(across all samples & heads)')
    plt.tight_layout()
    
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"\nâœ“ Attention heatmap saved: {save_path}")


def visualize_variable_importance(
    var_importance: np.ndarray,
    feature_names: list = None,
    top_k: int = 20,
    save_path: str = "variable_importance.png"
):
    """
    Variable importance ì‹œê°í™”
    
    Args:
        var_importance: variable importance array (epochs saved)
        feature_names: feature ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (optional)
        top_k: ìƒìœ„ ëª‡ ê°œ
        save_path: ì €ì¥ ê²½ë¡œ
    """
    if var_importance is None or len(var_importance) == 0:
        print("\nâš ï¸  No variable importance to visualize")
        return
    
    # ë§ˆì§€ë§‰ epoch ì‚¬ìš©
    last_epoch = var_importance[-1]
    
    if len(last_epoch.shape) != 3:
        print(f"\nâš ï¸  Unexpected shape: {last_epoch.shape}")
        return
    
    # í‰ê·  importance
    avg_importance = last_epoch.mean(axis=(0, 1))
    
    # Top k ì¶”ì¶œ
    top_indices = np.argsort(avg_importance)[-top_k:][::-1]
    top_values = avg_importance[top_indices]
    
    # Feature ì´ë¦„
    if feature_names is not None:
        top_names = [feature_names[i] if i < len(feature_names) else f'Feature {i}' 
                     for i in top_indices]
    else:
        top_names = [f'Feature {i}' for i in top_indices]
    
    # ì‹œê°í™”
    plt.figure(figsize=(12, 8))
    plt.barh(range(len(top_values)), top_values, color='steelblue')
    plt.yticks(range(len(top_values)), top_names)
    plt.xlabel('Importance Score')
    plt.title(f'Top {top_k} Variable Importance')
    plt.gca().invert_yaxis()
    plt.grid(axis='x', alpha=0.3)
    plt.tight_layout()
    
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"\nâœ“ Variable importance plot saved: {save_path}")


def main():
    parser = argparse.ArgumentParser(description='View TFT interpretation.npz file')
    parser.add_argument('--interp_file', type=str, required=True,
                       help='Path to fold_X_interpretation.npz')
    parser.add_argument('--output_dir', type=str, default='./interpretation_analysis',
                       help='Output directory for plots')
    parser.add_argument('--top_k', type=int, default=20,
                       help='Number of top features to show')
    
    args = parser.parse_args()
    
    # íŒŒì¼ ë¡œë“œ
    data = load_interpretation_file(args.interp_file)
    
    # Variable importance ë¶„ì„
    var_importance = analyze_variable_importance(data)
    
    # Attention weights ë¶„ì„
    attn_weights = analyze_attention_weights(data)
    
    # ì‹œê°í™”
    Path(args.output_dir).mkdir(parents=True, exist_ok=True)
    
    if attn_weights is not None:
        visualize_attention_heatmap(
            attn_weights,
            save_path=str(Path(args.output_dir) / 'attention_heatmap.png')
        )
    
    if var_importance is not None:
        visualize_variable_importance(
            var_importance,
            top_k=args.top_k,
            save_path=str(Path(args.output_dir) / f'top{args.top_k}_variable_importance.png')
        )
    
    print(f"\n{'='*60}")
    print("âœ… Analysis completed!")
    print(f"{'='*60}")
    print(f"\nOutputs saved to: {args.output_dir}/")
    print()


if __name__ == "__main__":
    main()
