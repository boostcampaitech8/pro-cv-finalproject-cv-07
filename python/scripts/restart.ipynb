{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba764dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/gluonts/json.py:102: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"/data/ephemeral/home/pro-cv-finalproject-cv-07/python\") \n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.configs.train_config import TrainConfig\n",
    "from src.utils.set_seed import set_seed\n",
    "from src.data.dataset import build_multi_item_dataset, deepar_split, lag_features_by_1day\n",
    "from collections import defaultdict\n",
    "import tyro\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from gluonts.torch.model.deepar import DeepAREstimator\n",
    "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
    "from pytorch_lightning.loggers import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c8562a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìÅ Loading Dataset\n",
      "============================================================\n",
      " corn: 3824 samples\n",
      " wheat: 2738 samples\n",
      " soybean: 2670 samples\n",
      " gold: 3643 samples\n",
      " silver: 3643 samples\n",
      " copper: 3643 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìÅ Loading Dataset\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "\n",
    "df={}\n",
    "for name in [\"corn\", \"wheat\", \"soybean\", \"gold\", \"silver\", \"copper\"]:\n",
    "    data_path = os.path.join(\"/data/ephemeral/home/pro-cv-finalproject-cv-07/python/src/datasets\", f\"preprocessing/{name}_feature_engineering.csv\")\n",
    "    data = pd.read_csv(data_path)\n",
    "    data[\"item_id\"] = name\n",
    "    data['time'] = pd.to_datetime(data['time'])\n",
    "    \n",
    "    df[name] = data\n",
    "  \n",
    "    \n",
    "    print(f\" {name}: {len(data)} samples\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2a3ba10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>EMA</th>\n",
       "      <th>Volume</th>\n",
       "      <th>log_return_1</th>\n",
       "      <th>log_return_5</th>\n",
       "      <th>log_return_10</th>\n",
       "      <th>...</th>\n",
       "      <th>timeframe_score_std</th>\n",
       "      <th>timeframe_score_max</th>\n",
       "      <th>timeframe_score_min</th>\n",
       "      <th>sentiment_neg_ratio</th>\n",
       "      <th>sentiment_neu_ratio</th>\n",
       "      <th>sentiment_pos_ratio</th>\n",
       "      <th>time_past_ratio</th>\n",
       "      <th>time_present_ratio</th>\n",
       "      <th>time_future_ratio</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>504.50</td>\n",
       "      <td>512.00</td>\n",
       "      <td>500.25</td>\n",
       "      <td>505.00</td>\n",
       "      <td>392.281730</td>\n",
       "      <td>187576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>corn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-09-23</td>\n",
       "      <td>506.25</td>\n",
       "      <td>507.00</td>\n",
       "      <td>495.25</td>\n",
       "      <td>499.25</td>\n",
       "      <td>393.346091</td>\n",
       "      <td>192998</td>\n",
       "      <td>-0.011451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.033219</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>corn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-09-24</td>\n",
       "      <td>498.75</td>\n",
       "      <td>523.50</td>\n",
       "      <td>496.50</td>\n",
       "      <td>521.75</td>\n",
       "      <td>394.623742</td>\n",
       "      <td>201964</td>\n",
       "      <td>0.044082</td>\n",
       "      <td>-0.007035</td>\n",
       "      <td>-0.002005</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>corn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-09-27</td>\n",
       "      <td>522.00</td>\n",
       "      <td>528.75</td>\n",
       "      <td>511.25</td>\n",
       "      <td>512.75</td>\n",
       "      <td>395.799127</td>\n",
       "      <td>176759</td>\n",
       "      <td>-0.017400</td>\n",
       "      <td>-0.113540</td>\n",
       "      <td>0.012381</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>corn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-09-28</td>\n",
       "      <td>512.00</td>\n",
       "      <td>513.50</td>\n",
       "      <td>499.50</td>\n",
       "      <td>500.00</td>\n",
       "      <td>396.835952</td>\n",
       "      <td>151856</td>\n",
       "      <td>-0.025180</td>\n",
       "      <td>-0.083869</td>\n",
       "      <td>0.080530</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>corn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>2025-11-20</td>\n",
       "      <td>429.75</td>\n",
       "      <td>431.25</td>\n",
       "      <td>425.75</td>\n",
       "      <td>426.50</td>\n",
       "      <td>428.042614</td>\n",
       "      <td>194578</td>\n",
       "      <td>-0.007591</td>\n",
       "      <td>-0.013470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>corn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>426.25</td>\n",
       "      <td>427.75</td>\n",
       "      <td>424.00</td>\n",
       "      <td>425.50</td>\n",
       "      <td>428.017315</td>\n",
       "      <td>194578</td>\n",
       "      <td>-0.002347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>corn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3821</th>\n",
       "      <td>2025-11-24</td>\n",
       "      <td>426.00</td>\n",
       "      <td>426.50</td>\n",
       "      <td>422.25</td>\n",
       "      <td>423.75</td>\n",
       "      <td>427.974854</td>\n",
       "      <td>175584</td>\n",
       "      <td>-0.004121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>corn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822</th>\n",
       "      <td>2025-11-25</td>\n",
       "      <td>423.75</td>\n",
       "      <td>426.00</td>\n",
       "      <td>422.25</td>\n",
       "      <td>423.50</td>\n",
       "      <td>427.930328</td>\n",
       "      <td>203255</td>\n",
       "      <td>-0.000590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>corn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823</th>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>423.00</td>\n",
       "      <td>424.25</td>\n",
       "      <td>423.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>427.891220</td>\n",
       "      <td>4205</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>corn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3824 rows √ó 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time    open    high     low   close         EMA  Volume  \\\n",
       "0    2010-09-22  504.50  512.00  500.25  505.00  392.281730  187576   \n",
       "1    2010-09-23  506.25  507.00  495.25  499.25  393.346091  192998   \n",
       "2    2010-09-24  498.75  523.50  496.50  521.75  394.623742  201964   \n",
       "3    2010-09-27  522.00  528.75  511.25  512.75  395.799127  176759   \n",
       "4    2010-09-28  512.00  513.50  499.50  500.00  396.835952  151856   \n",
       "...         ...     ...     ...     ...     ...         ...     ...   \n",
       "3819 2025-11-20  429.75  431.25  425.75  426.50  428.042614  194578   \n",
       "3820 2025-11-21  426.25  427.75  424.00  425.50  428.017315  194578   \n",
       "3821 2025-11-24  426.00  426.50  422.25  423.75  427.974854  175584   \n",
       "3822 2025-11-25  423.75  426.00  422.25  423.50  427.930328  203255   \n",
       "3823 2025-11-26  423.00  424.25  423.00  424.00  427.891220    4205   \n",
       "\n",
       "      log_return_1  log_return_5  log_return_10  ...  timeframe_score_std  \\\n",
       "0              NaN           NaN            NaN  ...                  NaN   \n",
       "1        -0.011451      0.000000      -0.033219  ...                  NaN   \n",
       "2         0.044082     -0.007035      -0.002005  ...                  NaN   \n",
       "3        -0.017400     -0.113540       0.012381  ...                  NaN   \n",
       "4        -0.025180     -0.083869       0.080530  ...                  NaN   \n",
       "...            ...           ...            ...  ...                  ...   \n",
       "3819     -0.007591     -0.013470            NaN  ...                  NaN   \n",
       "3820     -0.002347           NaN            NaN  ...                  NaN   \n",
       "3821     -0.004121           NaN            NaN  ...                  NaN   \n",
       "3822     -0.000590           NaN            NaN  ...                  NaN   \n",
       "3823      0.001180           NaN            NaN  ...                  NaN   \n",
       "\n",
       "      timeframe_score_max  timeframe_score_min  sentiment_neg_ratio  \\\n",
       "0                     NaN                  NaN                  NaN   \n",
       "1                     NaN                  NaN                  NaN   \n",
       "2                     NaN                  NaN                  NaN   \n",
       "3                     NaN                  NaN                  NaN   \n",
       "4                     NaN                  NaN                  NaN   \n",
       "...                   ...                  ...                  ...   \n",
       "3819                  NaN                  NaN                  NaN   \n",
       "3820                  NaN                  NaN                  NaN   \n",
       "3821                  NaN                  NaN                  NaN   \n",
       "3822                  NaN                  NaN                  NaN   \n",
       "3823                  NaN                  NaN                  NaN   \n",
       "\n",
       "      sentiment_neu_ratio  sentiment_pos_ratio  time_past_ratio  \\\n",
       "0                     NaN                  NaN              NaN   \n",
       "1                     NaN                  NaN              NaN   \n",
       "2                     NaN                  NaN              NaN   \n",
       "3                     NaN                  NaN              NaN   \n",
       "4                     NaN                  NaN              NaN   \n",
       "...                   ...                  ...              ...   \n",
       "3819                  NaN                  NaN              NaN   \n",
       "3820                  NaN                  NaN              NaN   \n",
       "3821                  NaN                  NaN              NaN   \n",
       "3822                  NaN                  NaN              NaN   \n",
       "3823                  NaN                  NaN              NaN   \n",
       "\n",
       "      time_present_ratio  time_future_ratio  item_id  \n",
       "0                    NaN                NaN     corn  \n",
       "1                    NaN                NaN     corn  \n",
       "2                    NaN                NaN     corn  \n",
       "3                    NaN                NaN     corn  \n",
       "4                    NaN                NaN     corn  \n",
       "...                  ...                ...      ...  \n",
       "3819                 NaN                NaN     corn  \n",
       "3820                 NaN                NaN     corn  \n",
       "3821                 NaN                NaN     corn  \n",
       "3822                 NaN                NaN     corn  \n",
       "3823                 NaN                NaN     corn  \n",
       "\n",
       "[3824 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['corn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1dc15cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(arr)):\n",
    "    if arr[i]>100:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3beba7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling PyTorch because PyTorch >= 2.2 is required but found 2.1.0\n",
      "PyTorch was not found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(freq: str, prediction_length: int, context_length: Optional[int] = None, num_layers: int = 2, hidden_size: int = 40, lr: float = 0.001, weight_decay: float = 1e-08, dropout_rate: float = 0.1, patience: int = 10, num_feat_dynamic_real: int = 0, num_feat_static_cat: int = 0, num_feat_static_real: int = 0, cardinality: Optional[List[int]] = None, embedding_dimension: Optional[List[int]] = None, distr_output: gluonts.torch.distributions.distribution_output.DistributionOutput = gluonts.torch.distributions.studentT.StudentTOutput(beta=0.0), scaling: bool = True, default_scale: Optional[float] = None, lags_seq: Optional[List[int]] = None, time_features: Optional[List[Callable[[pandas.core.indexes.period.PeriodIndex], numpy.ndarray]]] = None, num_parallel_samples: int = 100, batch_size: int = 32, num_batches_per_epoch: int = 50, imputation_method: Optional[gluonts.transform.feature.MissingValueImputation] = None, trainer_kwargs: Optional[Dict[str, Any]] = None, train_sampler: Optional[gluonts.transform.sampler.InstanceSampler] = None, validation_sampler: Optional[gluonts.transform.sampler.InstanceSampler] = None, nonnegative_pred_samples: bool = False) -> None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/gluonts/json.py:102: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from gluonts.torch.model.deepar import DeepAREstimator\n",
    "print(inspect.signature(DeepAREstimator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec585ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n",
      "open\n",
      "high\n",
      "low\n",
      "close\n",
      "EMA\n",
      "Volume\n",
      "log_return_1\n",
      "log_return_5\n",
      "log_return_10\n",
      "log_return_20\n",
      "EMA_5\n",
      "EMA_10\n",
      "EMA_20\n",
      "EMA_50\n",
      "EMA_100\n",
      "vol_return_7d\n",
      "vol_volume_7d\n",
      "vol_return_14d\n",
      "vol_volume_14d\n",
      "vol_return_21d\n",
      "vol_volume_21d\n",
      "news_count\n",
      "sentiment_score_mean\n",
      "sentiment_score_std\n",
      "sentiment_score_max\n",
      "sentiment_score_min\n",
      "timeframe_score_mean\n",
      "timeframe_score_std\n",
      "timeframe_score_max\n",
      "timeframe_score_min\n",
      "sentiment_neg_ratio\n",
      "sentiment_neu_ratio\n",
      "sentiment_pos_ratio\n",
      "time_past_ratio\n",
      "time_present_ratio\n",
      "time_future_ratio\n",
      "item_id\n"
     ]
    }
   ],
   "source": [
    "for a,i in df['soybean'].items():\n",
    "    print(a)\n",
    "    arr.append(sum(i.isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8825a1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['soybean']['time_future_ratio'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c877f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "        c for c in pd.concat(df.values(), ignore_index=True).columns\n",
    "        if c not in [\"time\", \"item_id\", \"close\"] and not c.startswith(\"log_return_\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd9b5739",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in list(df.keys()):\n",
    "    df[name] = lag_features_by_1day(df[name], feature_cols, group_col=\"item_id\", time_col=\"time\")\n",
    "    # Ïó¨Í∏∞ÏÑú 1day Îï°Í∏∏Îïå ÏóÜÏï†Î©¥ ÏïàÎêòÏûñÏïÑ ÏóÜÏï†Ïûê ÏãúÏõêÌïòÍ≤å\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1cfd1fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorn\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['corn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec03726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item_id, dfs in df.items():          \n",
    "    dfs = dfs.sort_values(\"time\").reset_index(drop=True)\n",
    "\n",
    "    dfs[\"time_idx\"] = np.arange(len(dfs), dtype=np.int64)\n",
    "\n",
    "    df[item_id] = dfs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "175bbb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corn':            time    open    high     low   close         EMA    Volume  \\\n",
       " 0    2017-11-10  347.50  349.75  340.75  343.50  359.237260  475087.0   \n",
       " 1    2017-11-13  341.75  344.00  341.00  342.25  359.080670  349164.0   \n",
       " 2    2017-11-14  343.50  344.00  341.50  337.50  358.913201  289722.0   \n",
       " 3    2017-11-15  342.00  342.25  337.25  338.25  358.700134  220983.0   \n",
       " 4    2017-11-16  337.25  339.00  337.00  336.50  358.496650  217010.0   \n",
       " ...         ...     ...     ...     ...     ...         ...       ...   \n",
       " 2012 2025-11-11  426.75  431.25  426.25  432.00  427.605082  220392.0   \n",
       " 2013 2025-11-12  429.00  432.75  428.50  435.25  427.648812  221848.0   \n",
       " 2014 2025-11-13  431.50  436.00  431.00  441.50  427.724446  271699.0   \n",
       " 2015 2025-11-14  434.75  442.75  434.00  430.25  427.861516  400924.0   \n",
       " 2016 2025-11-17  441.50  442.75  429.50  434.75  427.885282  388692.0   \n",
       " \n",
       "       log_return_1  log_return_5  log_return_10  ...  timeframe_score_max  \\\n",
       " 0         0.005839     -0.014750       0.002194  ...             0.999669   \n",
       " 1        -0.003646     -0.001457      -0.013925  ...             0.999777   \n",
       " 2        -0.013976      0.008003      -0.017687  ...             0.999794   \n",
       " 3         0.002220      0.021979       0.004435  ...             0.999750   \n",
       " 4        -0.005187      0.020484       0.050443  ...             0.999781   \n",
       " ...            ...           ...            ...  ...                  ...   \n",
       " 2012      0.005222      0.011568      -0.014060  ...             0.999748   \n",
       " 2013      0.007495      0.010935      -0.019872  ...             0.999771   \n",
       " 2014      0.014257     -0.012717      -0.026187  ...             0.999783   \n",
       " 2015     -0.025812     -0.034566            NaN  ...             0.999775   \n",
       " 2016      0.010405     -0.011101            NaN  ...             0.999761   \n",
       " \n",
       "       timeframe_score_min  sentiment_neg_ratio  sentiment_neu_ratio  \\\n",
       " 0                0.716598             0.222222             0.666667   \n",
       " 1                0.596294             0.101695             0.694915   \n",
       " 2                0.509389             0.169811             0.547170   \n",
       " 3                0.524745             0.132075             0.603774   \n",
       " 4                0.545537             0.274510             0.490196   \n",
       " ...                   ...                  ...                  ...   \n",
       " 2012             0.647249             0.153846             0.346154   \n",
       " 2013             0.722270             0.285714             0.321429   \n",
       " 2014             0.661313             0.192308             0.230769   \n",
       " 2015             0.639835             0.214286             0.250000   \n",
       " 2016             0.546319             0.230769             0.307692   \n",
       " \n",
       "       sentiment_pos_ratio  time_past_ratio  time_present_ratio  \\\n",
       " 0                0.111111         0.111111            0.222222   \n",
       " 1                0.203390         0.118644            0.101695   \n",
       " 2                0.283019         0.207547            0.150943   \n",
       " 3                0.264151         0.094340            0.188679   \n",
       " 4                0.235294         0.137255            0.058824   \n",
       " ...                   ...              ...                 ...   \n",
       " 2012             0.500000         0.076923            0.115385   \n",
       " 2013             0.392857         0.000000            0.178571   \n",
       " 2014             0.576923         0.192308            0.076923   \n",
       " 2015             0.535714         0.071429            0.214286   \n",
       " 2016             0.461538         0.076923            0.153846   \n",
       " \n",
       "       time_future_ratio  item_id  time_idx  \n",
       " 0              0.666667     corn         0  \n",
       " 1              0.779661     corn         1  \n",
       " 2              0.641509     corn         2  \n",
       " 3              0.716981     corn         3  \n",
       " 4              0.803922     corn         4  \n",
       " ...                 ...      ...       ...  \n",
       " 2012           0.807692     corn      2012  \n",
       " 2013           0.821429     corn      2013  \n",
       " 2014           0.730769     corn      2014  \n",
       " 2015           0.714286     corn      2015  \n",
       " 2016           0.769231     corn      2016  \n",
       " \n",
       " [2017 rows x 39 columns],\n",
       " 'wheat':            time    open    high     low   close         EMA    Volume  \\\n",
       " 0    2017-11-10  425.75  432.00  423.75  431.50  444.523135  155471.0   \n",
       " 1    2017-11-13  429.50  434.25  426.75  424.25  444.393552  105996.0   \n",
       " 2    2017-11-14  432.00  432.00  422.25  428.00  444.193118  110242.0   \n",
       " 3    2017-11-15  424.75  429.50  423.25  420.00  444.031993   93367.0   \n",
       " 4    2017-11-16  427.75  428.25  418.00  438.00  443.792868   76382.0   \n",
       " ...         ...     ...     ...     ...     ...         ...       ...   \n",
       " 2012 2025-11-11  528.00  537.25  527.50  536.00  536.050504   92410.0   \n",
       " 2013 2025-11-12  535.75  539.00  531.25  536.00  536.050001   80355.0   \n",
       " 2014 2025-11-13  536.00  536.75  527.50  535.75  536.049504   95686.0   \n",
       " 2015 2025-11-14  536.25  539.25  530.75  541.50  536.046523   92763.0   \n",
       " 2016 2025-11-17  552.25  558.75  539.50  558.50  536.100787   93881.0   \n",
       " \n",
       "       log_return_1  log_return_5  log_return_10  ...  timeframe_score_max  \\\n",
       " 0         0.005811      0.020762       0.013314  ...             0.999669   \n",
       " 1        -0.016945      0.027430      -0.007560  ...             0.999777   \n",
       " 2         0.008800      0.033037       0.011717  ...             0.999794   \n",
       " 3        -0.018868      0.030488       0.015648  ...             0.999750   \n",
       " 4         0.041964      0.048223       0.030483  ...             0.999781   \n",
       " ...            ...           ...            ...  ...                  ...   \n",
       " 2012      0.000467      0.041587      -0.001868  ...             0.999748   \n",
       " 2013      0.000000      0.042015       0.006045  ...             0.999771   \n",
       " 2014     -0.000467      0.024875       0.003260  ...             0.999783   \n",
       " 2015      0.010675      0.009289            NaN  ...             0.999775   \n",
       " 2016      0.030912     -0.003237            NaN  ...             0.999761   \n",
       " \n",
       "       timeframe_score_min  sentiment_neg_ratio  sentiment_neu_ratio  \\\n",
       " 0                0.716598             0.222222             0.666667   \n",
       " 1                0.596294             0.101695             0.694915   \n",
       " 2                0.509389             0.169811             0.547170   \n",
       " 3                0.524745             0.132075             0.603774   \n",
       " 4                0.545537             0.274510             0.490196   \n",
       " ...                   ...                  ...                  ...   \n",
       " 2012             0.647249             0.153846             0.346154   \n",
       " 2013             0.722270             0.285714             0.321429   \n",
       " 2014             0.661313             0.192308             0.230769   \n",
       " 2015             0.639835             0.214286             0.250000   \n",
       " 2016             0.546319             0.230769             0.307692   \n",
       " \n",
       "       sentiment_pos_ratio  time_past_ratio  time_present_ratio  \\\n",
       " 0                0.111111         0.111111            0.222222   \n",
       " 1                0.203390         0.118644            0.101695   \n",
       " 2                0.283019         0.207547            0.150943   \n",
       " 3                0.264151         0.094340            0.188679   \n",
       " 4                0.235294         0.137255            0.058824   \n",
       " ...                   ...              ...                 ...   \n",
       " 2012             0.500000         0.076923            0.115385   \n",
       " 2013             0.392857         0.000000            0.178571   \n",
       " 2014             0.576923         0.192308            0.076923   \n",
       " 2015             0.535714         0.071429            0.214286   \n",
       " 2016             0.461538         0.076923            0.153846   \n",
       " \n",
       "       time_future_ratio  item_id  time_idx  \n",
       " 0              0.666667    wheat         0  \n",
       " 1              0.779661    wheat         1  \n",
       " 2              0.641509    wheat         2  \n",
       " 3              0.716981    wheat         3  \n",
       " 4              0.803922    wheat         4  \n",
       " ...                 ...      ...       ...  \n",
       " 2012           0.807692    wheat      2012  \n",
       " 2013           0.821429    wheat      2013  \n",
       " 2014           0.730769    wheat      2014  \n",
       " 2015           0.714286    wheat      2015  \n",
       " 2016           0.769231    wheat      2016  \n",
       " \n",
       " [2017 rows x 39 columns],\n",
       " 'soybean':            time   open   high    low  close         EMA   Volume  \\\n",
       " 0    2017-11-10  315.2  321.9  311.4  314.5  315.541184  85255.0   \n",
       " 1    2017-11-13  312.3  315.3  311.6  311.3  315.530824  41046.0   \n",
       " 2    2017-11-14  314.5  316.5  311.1  310.3  315.488727  51553.0   \n",
       " 3    2017-11-15  311.6  312.5  309.6  311.3  315.437098  52484.0   \n",
       " 4    2017-11-16  310.6  313.3  310.1  312.5  315.395932  47624.0   \n",
       " ...         ...    ...    ...    ...    ...         ...      ...   \n",
       " 2012 2025-11-11  317.0  320.2  316.3  316.9  295.512637  60119.0   \n",
       " 2013 2025-11-12  319.5  320.4  315.9  321.0  295.725446  64287.0   \n",
       " 2014 2025-11-13  316.9  322.2  315.4  328.4  295.976934  67357.0   \n",
       " 2015 2025-11-14  321.0  330.2  320.2  324.6  296.299552  78461.0   \n",
       " 2016 2025-11-17  330.1  332.3  323.7  332.6  296.581149  60273.0   \n",
       " \n",
       "       log_return_1  log_return_5  log_return_10  ...  timeframe_score_max  \\\n",
       " 0         0.008622      0.002243       0.044229  ...             0.999669   \n",
       " 1        -0.010227      0.017337       0.045985  ...             0.999777   \n",
       " 2        -0.003218      0.033794       0.045527  ...             0.999794   \n",
       " 3         0.003218      0.032031       0.053338  ...             0.999750   \n",
       " 4         0.003847      0.048285       0.047673  ...             0.999781   \n",
       " ...            ...           ...            ...  ...                  ...   \n",
       " 2012     -0.009735      0.038620      -0.005327  ...             0.999748   \n",
       " 2013      0.012855      0.035951       0.010984  ...             0.999771   \n",
       " 2014      0.022791      0.002178      -0.000623  ...             0.999783   \n",
       " 2015     -0.011639     -0.033440            NaN  ...             0.999775   \n",
       " 2016      0.024347     -0.016776            NaN  ...             0.999761   \n",
       " \n",
       "       timeframe_score_min  sentiment_neg_ratio  sentiment_neu_ratio  \\\n",
       " 0                0.716598             0.222222             0.666667   \n",
       " 1                0.596294             0.101695             0.694915   \n",
       " 2                0.509389             0.169811             0.547170   \n",
       " 3                0.524745             0.132075             0.603774   \n",
       " 4                0.545537             0.274510             0.490196   \n",
       " ...                   ...                  ...                  ...   \n",
       " 2012             0.647249             0.153846             0.346154   \n",
       " 2013             0.722270             0.285714             0.321429   \n",
       " 2014             0.661313             0.192308             0.230769   \n",
       " 2015             0.639835             0.214286             0.250000   \n",
       " 2016             0.546319             0.230769             0.307692   \n",
       " \n",
       "       sentiment_pos_ratio  time_past_ratio  time_present_ratio  \\\n",
       " 0                0.111111         0.111111            0.222222   \n",
       " 1                0.203390         0.118644            0.101695   \n",
       " 2                0.283019         0.207547            0.150943   \n",
       " 3                0.264151         0.094340            0.188679   \n",
       " 4                0.235294         0.137255            0.058824   \n",
       " ...                   ...              ...                 ...   \n",
       " 2012             0.500000         0.076923            0.115385   \n",
       " 2013             0.392857         0.000000            0.178571   \n",
       " 2014             0.576923         0.192308            0.076923   \n",
       " 2015             0.535714         0.071429            0.214286   \n",
       " 2016             0.461538         0.076923            0.153846   \n",
       " \n",
       "       time_future_ratio  item_id  time_idx  \n",
       " 0              0.666667  soybean         0  \n",
       " 1              0.779661  soybean         1  \n",
       " 2              0.641509  soybean         2  \n",
       " 3              0.716981  soybean         3  \n",
       " 4              0.803922  soybean         4  \n",
       " ...                 ...      ...       ...  \n",
       " 2012           0.807692  soybean      2012  \n",
       " 2013           0.821429  soybean      2013  \n",
       " 2014           0.730769  soybean      2014  \n",
       " 2015           0.714286  soybean      2015  \n",
       " 2016           0.769231  soybean      2016  \n",
       " \n",
       " [2017 rows x 39 columns],\n",
       " 'gold':            time    open    high     low   close          EMA    Volume  \\\n",
       " 0    2017-11-10  1282.1  1289.5  1280.5  1274.2  1269.321830  394181.0   \n",
       " 1    2017-11-13  1286.0  1287.7  1273.6  1278.9  1269.370369  354580.0   \n",
       " 2    2017-11-14  1275.3  1279.9  1274.4  1282.9  1269.465191  220906.0   \n",
       " 3    2017-11-15  1278.9  1283.8  1269.7  1277.7  1269.598870  355197.0   \n",
       " 4    2017-11-16  1280.7  1290.0  1276.5  1278.2  1269.679479  433647.0   \n",
       " ...         ...     ...     ...     ...     ...          ...       ...   \n",
       " 2012 2025-11-11  4007.2  4124.0  4004.2  4116.3  3439.345068  253812.0   \n",
       " 2013 2025-11-12  4124.0  4155.0  4102.8  4213.6  3446.080938  252249.0   \n",
       " 2014 2025-11-13  4132.2  4218.5  4104.4  4194.5  3453.717944  296796.0   \n",
       " 2015 2025-11-14  4202.4  4250.0  4148.5  4094.2  3461.088910  319216.0   \n",
       " 2016 2025-11-17  4174.9  4215.1  4032.6  4074.5  3467.388523  342176.0   \n",
       " \n",
       "       log_return_1  log_return_5  log_return_10  ...  timeframe_score_max  \\\n",
       " 0        -0.010384     -0.007250      -0.000155  ...             0.999669   \n",
       " 1         0.003682      0.017350       0.015729  ...             0.999777   \n",
       " 2         0.003123     -0.002819       0.012433  ...             0.999794   \n",
       " 3        -0.004062     -0.000936       0.002569  ...             0.999750   \n",
       " 4         0.000391      0.011285      -0.000783  ...             0.999781   \n",
       " ...            ...           ...            ...  ...                  ...   \n",
       " 2012     -0.001384     -0.011590      -0.006767  ...             0.999748   \n",
       " 2013      0.023363     -0.012172       0.005741  ...             0.999771   \n",
       " 2014     -0.004543     -0.031534      -0.002685  ...             0.999783   \n",
       " 2015     -0.024203     -0.032591       0.014297  ...             0.999775   \n",
       " 2016     -0.004823     -0.003597       0.043166  ...             0.999761   \n",
       " \n",
       "       timeframe_score_min  sentiment_neg_ratio  sentiment_neu_ratio  \\\n",
       " 0                0.716598             0.222222             0.666667   \n",
       " 1                0.596294             0.101695             0.694915   \n",
       " 2                0.509389             0.169811             0.547170   \n",
       " 3                0.524745             0.132075             0.603774   \n",
       " 4                0.545537             0.274510             0.490196   \n",
       " ...                   ...                  ...                  ...   \n",
       " 2012             0.647249             0.153846             0.346154   \n",
       " 2013             0.722270             0.285714             0.321429   \n",
       " 2014             0.661313             0.192308             0.230769   \n",
       " 2015             0.639835             0.214286             0.250000   \n",
       " 2016             0.546319             0.230769             0.307692   \n",
       " \n",
       "       sentiment_pos_ratio  time_past_ratio  time_present_ratio  \\\n",
       " 0                0.111111         0.111111            0.222222   \n",
       " 1                0.203390         0.118644            0.101695   \n",
       " 2                0.283019         0.207547            0.150943   \n",
       " 3                0.264151         0.094340            0.188679   \n",
       " 4                0.235294         0.137255            0.058824   \n",
       " ...                   ...              ...                 ...   \n",
       " 2012             0.500000         0.076923            0.115385   \n",
       " 2013             0.392857         0.000000            0.178571   \n",
       " 2014             0.576923         0.192308            0.076923   \n",
       " 2015             0.535714         0.071429            0.214286   \n",
       " 2016             0.461538         0.076923            0.153846   \n",
       " \n",
       "       time_future_ratio  item_id  time_idx  \n",
       " 0              0.666667     gold         0  \n",
       " 1              0.779661     gold         1  \n",
       " 2              0.641509     gold         2  \n",
       " 3              0.716981     gold         3  \n",
       " 4              0.803922     gold         4  \n",
       " ...                 ...      ...       ...  \n",
       " 2012           0.807692     gold      2012  \n",
       " 2013           0.821429     gold      2013  \n",
       " 2014           0.730769     gold      2014  \n",
       " 2015           0.714286     gold      2015  \n",
       " 2016           0.769231     gold      2016  \n",
       " \n",
       " [2017 rows x 39 columns],\n",
       " 'silver':            time    open    high     low   close        EMA    Volume  \\\n",
       " 0    2017-11-10  17.060  17.145  16.910  16.871  17.100300  101133.0   \n",
       " 1    2017-11-13  16.995  17.095  16.785  17.047  17.098018   92239.0   \n",
       " 2    2017-11-14  16.860  17.070  16.820  17.073  17.097511   71765.0   \n",
       " 3    2017-11-15  17.060  17.095  16.860  16.971  17.097267   74762.0   \n",
       " 4    2017-11-16  17.025  17.205  16.940  17.072  17.096010  103792.0   \n",
       " ...         ...     ...     ...     ...     ...        ...       ...   \n",
       " 2012 2025-11-11  48.295  50.480  48.235  50.744  39.247433   81072.0   \n",
       " 2013 2025-11-12  50.445  51.130  50.150  53.457  39.361826   72739.0   \n",
       " 2014 2025-11-13  51.075  53.625  50.760  53.170  39.502077  105123.0   \n",
       " 2015 2025-11-14  53.275  54.415  51.985  50.686  39.638076  126578.0   \n",
       " 2016 2025-11-17  52.200  53.375  49.860  50.711  39.748006  130252.0   \n",
       " \n",
       "       log_return_1  log_return_5  log_return_10  ...  timeframe_score_max  \\\n",
       " 0        -0.006146      0.005698       0.001001  ...             0.999669   \n",
       " 1         0.010378      0.029321       0.008793  ...             0.999777   \n",
       " 2         0.001524     -0.012098      -0.013287  ...             0.999794   \n",
       " 3        -0.005992     -0.006641      -0.030448  ...             0.999750   \n",
       " 4         0.005934      0.008274      -0.029723  ...             0.999781   \n",
       " ...            ...           ...            ...  ...                  ...   \n",
       " 2012      0.008570      0.007919       0.000298  ...             0.999748   \n",
       " 2013      0.052084     -0.004404       0.004346  ...             0.999771   \n",
       " 2014     -0.005383     -0.049919       0.002802  ...             0.999783   \n",
       " 2015     -0.047845     -0.055469       0.072413  ...             0.999775   \n",
       " 2016      0.000493     -0.015368       0.154292  ...             0.999761   \n",
       " \n",
       "       timeframe_score_min  sentiment_neg_ratio  sentiment_neu_ratio  \\\n",
       " 0                0.716598             0.222222             0.666667   \n",
       " 1                0.596294             0.101695             0.694915   \n",
       " 2                0.509389             0.169811             0.547170   \n",
       " 3                0.524745             0.132075             0.603774   \n",
       " 4                0.545537             0.274510             0.490196   \n",
       " ...                   ...                  ...                  ...   \n",
       " 2012             0.647249             0.153846             0.346154   \n",
       " 2013             0.722270             0.285714             0.321429   \n",
       " 2014             0.661313             0.192308             0.230769   \n",
       " 2015             0.639835             0.214286             0.250000   \n",
       " 2016             0.546319             0.230769             0.307692   \n",
       " \n",
       "       sentiment_pos_ratio  time_past_ratio  time_present_ratio  \\\n",
       " 0                0.111111         0.111111            0.222222   \n",
       " 1                0.203390         0.118644            0.101695   \n",
       " 2                0.283019         0.207547            0.150943   \n",
       " 3                0.264151         0.094340            0.188679   \n",
       " 4                0.235294         0.137255            0.058824   \n",
       " ...                   ...              ...                 ...   \n",
       " 2012             0.500000         0.076923            0.115385   \n",
       " 2013             0.392857         0.000000            0.178571   \n",
       " 2014             0.576923         0.192308            0.076923   \n",
       " 2015             0.535714         0.071429            0.214286   \n",
       " 2016             0.461538         0.076923            0.153846   \n",
       " \n",
       "       time_future_ratio  item_id  time_idx  \n",
       " 0              0.666667   silver         0  \n",
       " 1              0.779661   silver         1  \n",
       " 2              0.641509   silver         2  \n",
       " 3              0.716981   silver         3  \n",
       " 4              0.803922   silver         4  \n",
       " ...                 ...      ...       ...  \n",
       " 2012           0.807692   silver      2012  \n",
       " 2013           0.821429   silver      2013  \n",
       " 2014           0.730769   silver      2014  \n",
       " 2015           0.714286   silver      2015  \n",
       " 2016           0.769231   silver      2016  \n",
       " \n",
       " [2017 rows x 39 columns],\n",
       " 'copper':            time    open    high     low   close       EMA    Volume  \\\n",
       " 0    2017-11-10  3.0980  3.1075  3.0585  3.0760  2.810663  110864.0   \n",
       " 1    2017-11-13  3.0890  3.1095  3.0670  3.1165  2.813303   88740.0   \n",
       " 2    2017-11-14  3.0750  3.1365  3.0680  3.0650  2.816320  119706.0   \n",
       " 3    2017-11-15  3.1240  3.1285  3.0485  3.0545  2.818794  136156.0   \n",
       " 4    2017-11-16  3.0525  3.0645  3.0340  3.0480  2.821140  111057.0   \n",
       " ...         ...     ...     ...     ...     ...       ...       ...   \n",
       " 2012 2025-11-11  4.9700  5.1200  4.9670  5.0660  4.784008   67118.0   \n",
       " 2013 2025-11-12  5.0955  5.1045  5.0520  5.1055  4.786814   41745.0   \n",
       " 2014 2025-11-13  5.0635  5.1505  5.0250  5.1020  4.789985   56923.0   \n",
       " 2015 2025-11-14  5.0925  5.1630  5.0365  5.0630  4.793090   49072.0   \n",
       " 2016 2025-11-17  5.0615  5.0920  5.0020  5.0120  4.795775   52632.0   \n",
       " \n",
       "       log_return_1  log_return_5  log_return_10  ...  timeframe_score_max  \\\n",
       " 0        -0.003246     -0.012390       0.026540  ...             0.999669   \n",
       " 1         0.013081     -0.002930       0.018840  ...             0.999777   \n",
       " 2        -0.016663     -0.007569      -0.014545  ...             0.999794   \n",
       " 3        -0.003432      0.020506       0.001141  ...             0.999750   \n",
       " 4        -0.002130      0.026651       0.003105  ...             0.999781   \n",
       " ...            ...           ...            ...  ...                  ...   \n",
       " 2012     -0.007865     -0.018581      -0.027500  ...             0.999748   \n",
       " 2013      0.007767     -0.018327      -0.012514  ...             0.999771   \n",
       " 2014     -0.000686     -0.017187       0.017186  ...             0.999783   \n",
       " 2015     -0.007673     -0.026515       0.032777  ...             0.999775   \n",
       " 2016     -0.010124     -0.009526       0.046314  ...             0.999761   \n",
       " \n",
       "       timeframe_score_min  sentiment_neg_ratio  sentiment_neu_ratio  \\\n",
       " 0                0.716598             0.222222             0.666667   \n",
       " 1                0.596294             0.101695             0.694915   \n",
       " 2                0.509389             0.169811             0.547170   \n",
       " 3                0.524745             0.132075             0.603774   \n",
       " 4                0.545537             0.274510             0.490196   \n",
       " ...                   ...                  ...                  ...   \n",
       " 2012             0.647249             0.153846             0.346154   \n",
       " 2013             0.722270             0.285714             0.321429   \n",
       " 2014             0.661313             0.192308             0.230769   \n",
       " 2015             0.639835             0.214286             0.250000   \n",
       " 2016             0.546319             0.230769             0.307692   \n",
       " \n",
       "       sentiment_pos_ratio  time_past_ratio  time_present_ratio  \\\n",
       " 0                0.111111         0.111111            0.222222   \n",
       " 1                0.203390         0.118644            0.101695   \n",
       " 2                0.283019         0.207547            0.150943   \n",
       " 3                0.264151         0.094340            0.188679   \n",
       " 4                0.235294         0.137255            0.058824   \n",
       " ...                   ...              ...                 ...   \n",
       " 2012             0.500000         0.076923            0.115385   \n",
       " 2013             0.392857         0.000000            0.178571   \n",
       " 2014             0.576923         0.192308            0.076923   \n",
       " 2015             0.535714         0.071429            0.214286   \n",
       " 2016             0.461538         0.076923            0.153846   \n",
       " \n",
       "       time_future_ratio  item_id  time_idx  \n",
       " 0              0.666667   copper         0  \n",
       " 1              0.779661   copper         1  \n",
       " 2              0.641509   copper         2  \n",
       " 3              0.716981   copper         3  \n",
       " 4              0.803922   copper         4  \n",
       " ...                 ...      ...       ...  \n",
       " 2012           0.807692   copper      2012  \n",
       " 2013           0.821429   copper      2013  \n",
       " 2014           0.730769   copper      2014  \n",
       " 2015           0.714286   copper      2015  \n",
       " 2016           0.769231   copper      2016  \n",
       " \n",
       " [2017 rows x 39 columns]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f00d2282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gluonts.torch.model.deepar.estimator.DeepAREstimator'>\n",
      "<module 'gluonts.torch.model.deepar.estimator' from '/data/ephemeral/home/py310/lib/python3.10/site-packages/gluonts/torch/model/deepar/estimator.py'>\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(DeepAREstimator)\n",
    "print(inspect.getmodule(DeepAREstimator))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f06944c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorn\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['corn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19caef89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type        | Params | Mode  | FLOPs | In sizes                                                          | Out sizes  \n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | DeepARModel | 101 K  | train | 161 K | [[1, 1], [1, 1], [1, 1112, 35], [1, 1112], [1, 1112], [1, 5, 35]] | [1, 100, 5]\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.404     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "161 K     Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üîÑ Processing Fold 7\n",
      "============================================================\n",
      "Item: corn, rows=765, n_feat=31\n",
      "Item: corn, rows=126, n_feat=31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7086dbd1af0d4f63817f043aabd0d02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601605165a2648eebbf3c66e704eaeba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b5e787271b4d0abd9f4fcc4e46eb34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'val_loss' reached -3.23040 (best -3.23040), saving model to '/data/ephemeral/home/pro-cv-finalproject-cv-07/python/scripts/lightning_logs/version_14/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type        | Params | Mode  | FLOPs | In sizes                                                          | Out sizes  \n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | DeepARModel | 101 K  | train | 161 K | [[1, 1], [1, 1], [1, 1112, 35], [1, 1112], [1, 1112], [1, 5, 35]] | [1, 100, 5]\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.404     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "161 K     Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item: corn, rows=765, n_feat=31\n",
      "Item: wheat, rows=765, n_feat=31\n",
      "Item: corn, rows=126, n_feat=31\n",
      "Item: wheat, rows=126, n_feat=31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b26fec7ce0940ea972e80a9a1ba7f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bb636b6cab4ea8ad9f4f517fa4a1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600a1c34d8d5482283570593001934e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'val_loss' reached -2.98801 (best -2.98801), saving model to '/data/ephemeral/home/pro-cv-finalproject-cv-07/python/scripts/lightning_logs/version_15/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type        | Params | Mode  | FLOPs | In sizes                                                          | Out sizes  \n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | DeepARModel | 101 K  | train | 161 K | [[1, 1], [1, 1], [1, 1112, 35], [1, 1112], [1, 1112], [1, 5, 35]] | [1, 100, 5]\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.404     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "161 K     Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item: corn, rows=765, n_feat=31\n",
      "Item: wheat, rows=765, n_feat=31\n",
      "Item: soybean, rows=765, n_feat=31\n",
      "Item: corn, rows=126, n_feat=31\n",
      "Item: wheat, rows=126, n_feat=31\n",
      "Item: soybean, rows=126, n_feat=31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a5ccb779b442a29c6651f480108c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd78b8ee39a47fdad383a7d004fc41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea29143550e54b8ab8dc02877f2e0437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'val_loss' reached -3.04157 (best -3.04157), saving model to '/data/ephemeral/home/pro-cv-finalproject-cv-07/python/scripts/lightning_logs/version_16/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type        | Params | Mode  | FLOPs | In sizes                                                          | Out sizes  \n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | DeepARModel | 101 K  | train | 161 K | [[1, 1], [1, 1], [1, 1112, 35], [1, 1112], [1, 1112], [1, 5, 35]] | [1, 100, 5]\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.404     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "161 K     Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item: corn, rows=765, n_feat=31\n",
      "Item: wheat, rows=765, n_feat=31\n",
      "Item: soybean, rows=765, n_feat=31\n",
      "Item: gold, rows=765, n_feat=31\n",
      "Item: corn, rows=126, n_feat=31\n",
      "Item: wheat, rows=126, n_feat=31\n",
      "Item: soybean, rows=126, n_feat=31\n",
      "Item: gold, rows=126, n_feat=31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f5a8af2c2a45bea5f54718224a7e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4418def00d241588668c102b16f45b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9613b1b16d744a62ade37c53daf6fc6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'val_loss' reached -3.00402 (best -3.00402), saving model to '/data/ephemeral/home/pro-cv-finalproject-cv-07/python/scripts/lightning_logs/version_17/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type        | Params | Mode  | FLOPs | In sizes                                                          | Out sizes  \n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | DeepARModel | 101 K  | train | 161 K | [[1, 1], [1, 1], [1, 1112, 35], [1, 1112], [1, 1112], [1, 5, 35]] | [1, 100, 5]\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.404     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "161 K     Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item: corn, rows=765, n_feat=31\n",
      "Item: wheat, rows=765, n_feat=31\n",
      "Item: soybean, rows=765, n_feat=31\n",
      "Item: gold, rows=765, n_feat=31\n",
      "Item: silver, rows=765, n_feat=31\n",
      "Item: corn, rows=126, n_feat=31\n",
      "Item: wheat, rows=126, n_feat=31\n",
      "Item: soybean, rows=126, n_feat=31\n",
      "Item: gold, rows=126, n_feat=31\n",
      "Item: silver, rows=126, n_feat=31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b36bbe74a04dc79cd0dd9cb2bbbbec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1827939382cb49e997e4145d2fb407d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c242c0ba934fd5b0a07d2a1d661c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'val_loss' reached -2.89863 (best -2.89863), saving model to '/data/ephemeral/home/pro-cv-finalproject-cv-07/python/scripts/lightning_logs/version_18/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type        | Params | Mode  | FLOPs | In sizes                                                          | Out sizes  \n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | DeepARModel | 101 K  | train | 161 K | [[1, 1], [1, 1], [1, 1112, 35], [1, 1112], [1, 1112], [1, 5, 35]] | [1, 100, 5]\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.404     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "161 K     Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item: corn, rows=765, n_feat=31\n",
      "Item: wheat, rows=765, n_feat=31\n",
      "Item: soybean, rows=765, n_feat=31\n",
      "Item: gold, rows=765, n_feat=31\n",
      "Item: silver, rows=765, n_feat=31\n",
      "Item: copper, rows=765, n_feat=31\n",
      "Item: corn, rows=126, n_feat=31\n",
      "Item: wheat, rows=126, n_feat=31\n",
      "Item: soybean, rows=126, n_feat=31\n",
      "Item: gold, rows=126, n_feat=31\n",
      "Item: silver, rows=126, n_feat=31\n",
      "Item: copper, rows=126, n_feat=31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc1f7d31d7943429815d4c61cf9a4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df84f0f9fed44118f29d33459492d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce70927545ca4279848f1ab21b6cd47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'val_loss' reached -2.90106 (best -2.90106), saving model to '/data/ephemeral/home/pro-cv-finalproject-cv-07/python/scripts/lightning_logs/version_19/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "folds = [7] \n",
    "\n",
    "\n",
    "all_results_log = []\n",
    "all_results_close = []\n",
    "\n",
    "for fold in folds:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üîÑ Processing Fold {fold}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    train_dfs = {}\n",
    "    val_dfs = {}\n",
    "    \n",
    "    for name, dfs in df.items():\n",
    "        train_df, val_df = deepar_split(\n",
    "            dfs,\n",
    "            os.path.join(\"/data/ephemeral/home/pro-cv-finalproject-cv-07/python/src/datasets\", \"rolling_fold.json\"),\n",
    "            fold,\n",
    "        )\n",
    "        train_dfs[name] = train_df\n",
    "        val_dfs[name] = val_df\n",
    "        train_ds = build_multi_item_dataset(train_dfs,\"log_return_1\",feature_cols)\n",
    "        val_ds   = build_multi_item_dataset(val_dfs,\"log_return_1\",feature_cols)\n",
    "        estimator = DeepAREstimator(\n",
    "                freq=\"D\",\n",
    "                prediction_length=5,\n",
    "                context_length=20,\n",
    "                num_feat_dynamic_real=len(feature_cols),\n",
    "                num_layers=3,\n",
    "                hidden_size=64,\n",
    "                dropout_rate=0.1,\n",
    "                lr=1e-4,\n",
    "                trainer_kwargs={\n",
    "                    \"max_epochs\": 1,\n",
    "                    \"accelerator\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "                    \"devices\": 1,\n",
    "                    \"gradient_clip_val\": 1.0,\n",
    "                },\n",
    "            )\n",
    "            \n",
    "        predictor = estimator.train(\n",
    "            training_data=train_ds,\n",
    "            validation_data=val_ds\n",
    "        )\n",
    "\n",
    "        forecast_it, ts_it = make_evaluation_predictions(\n",
    "            dataset=val_ds,\n",
    "            predictor=predictor,\n",
    "            num_samples=200,\n",
    "        )\n",
    "        forecasts = list(forecast_it)\n",
    "        tss = list(ts_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc39dc0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PandasDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mval_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'PandasDataset' object is not subscriptable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d604e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> dict_keys(['start', 'target', 'item_id', 'feat_dynamic_real'])\n"
     ]
    }
   ],
   "source": [
    "first = list(val_ds)[0]\n",
    "print(type(first), first.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5df734ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>EMA</th>\n",
       "      <th>Volume</th>\n",
       "      <th>log_return_1</th>\n",
       "      <th>log_return_5</th>\n",
       "      <th>log_return_10</th>\n",
       "      <th>...</th>\n",
       "      <th>timeframe_score_max</th>\n",
       "      <th>timeframe_score_min</th>\n",
       "      <th>sentiment_neg_ratio</th>\n",
       "      <th>sentiment_neu_ratio</th>\n",
       "      <th>sentiment_pos_ratio</th>\n",
       "      <th>time_past_ratio</th>\n",
       "      <th>time_present_ratio</th>\n",
       "      <th>time_future_ratio</th>\n",
       "      <th>item_id</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-05-29</td>\n",
       "      <td>4.7600</td>\n",
       "      <td>4.9030</td>\n",
       "      <td>4.7510</td>\n",
       "      <td>4.7910</td>\n",
       "      <td>4.082686</td>\n",
       "      <td>101463.0</td>\n",
       "      <td>-0.013270</td>\n",
       "      <td>-0.067743</td>\n",
       "      <td>-0.073712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999774</td>\n",
       "      <td>0.496353</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>copper</td>\n",
       "      <td>1646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-05-30</td>\n",
       "      <td>4.8750</td>\n",
       "      <td>4.8935</td>\n",
       "      <td>4.7500</td>\n",
       "      <td>4.6585</td>\n",
       "      <td>4.089734</td>\n",
       "      <td>71896.0</td>\n",
       "      <td>-0.028046</td>\n",
       "      <td>-0.039379</td>\n",
       "      <td>-0.047883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>0.927121</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>copper</td>\n",
       "      <td>1647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>4.7810</td>\n",
       "      <td>4.7840</td>\n",
       "      <td>4.6205</td>\n",
       "      <td>4.6020</td>\n",
       "      <td>4.095393</td>\n",
       "      <td>84255.0</td>\n",
       "      <td>-0.012203</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>-0.038736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.613561</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>copper</td>\n",
       "      <td>1648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>4.6610</td>\n",
       "      <td>4.6735</td>\n",
       "      <td>4.5710</td>\n",
       "      <td>4.6675</td>\n",
       "      <td>4.100434</td>\n",
       "      <td>74629.0</td>\n",
       "      <td>0.014133</td>\n",
       "      <td>-0.026087</td>\n",
       "      <td>-0.023525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999794</td>\n",
       "      <td>0.575466</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>copper</td>\n",
       "      <td>1649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-06-04</td>\n",
       "      <td>4.6250</td>\n",
       "      <td>4.6920</td>\n",
       "      <td>4.5955</td>\n",
       "      <td>4.5370</td>\n",
       "      <td>4.106076</td>\n",
       "      <td>65807.0</td>\n",
       "      <td>-0.028358</td>\n",
       "      <td>-0.026926</td>\n",
       "      <td>-0.048281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>0.723079</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>copper</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2024-11-19</td>\n",
       "      <td>4.0665</td>\n",
       "      <td>4.1355</td>\n",
       "      <td>4.0505</td>\n",
       "      <td>4.1420</td>\n",
       "      <td>4.250191</td>\n",
       "      <td>50803.0</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>-0.004866</td>\n",
       "      <td>0.019707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999722</td>\n",
       "      <td>0.544919</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>copper</td>\n",
       "      <td>1767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>4.1240</td>\n",
       "      <td>4.1745</td>\n",
       "      <td>4.0885</td>\n",
       "      <td>4.1555</td>\n",
       "      <td>4.249115</td>\n",
       "      <td>50275.0</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>-0.022709</td>\n",
       "      <td>0.014263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>0.781507</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>copper</td>\n",
       "      <td>1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2024-11-21</td>\n",
       "      <td>4.1660</td>\n",
       "      <td>4.1790</td>\n",
       "      <td>4.1365</td>\n",
       "      <td>4.1250</td>\n",
       "      <td>4.248183</td>\n",
       "      <td>44315.0</td>\n",
       "      <td>-0.007367</td>\n",
       "      <td>-0.003979</td>\n",
       "      <td>0.008864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999761</td>\n",
       "      <td>0.638620</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>copper</td>\n",
       "      <td>1769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2024-11-22</td>\n",
       "      <td>4.1530</td>\n",
       "      <td>4.1665</td>\n",
       "      <td>4.0970</td>\n",
       "      <td>4.0860</td>\n",
       "      <td>4.246958</td>\n",
       "      <td>45938.0</td>\n",
       "      <td>-0.009500</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>0.017185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>0.868944</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>copper</td>\n",
       "      <td>1770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>4.1090</td>\n",
       "      <td>4.1195</td>\n",
       "      <td>4.0610</td>\n",
       "      <td>4.1000</td>\n",
       "      <td>4.245356</td>\n",
       "      <td>49185.0</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.010832</td>\n",
       "      <td>0.045335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>0.695777</td>\n",
       "      <td>0.209677</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.306452</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>copper</td>\n",
       "      <td>1771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows √ó 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          time    open    high     low   close       EMA    Volume  \\\n",
       "0   2024-05-29  4.7600  4.9030  4.7510  4.7910  4.082686  101463.0   \n",
       "1   2024-05-30  4.8750  4.8935  4.7500  4.6585  4.089734   71896.0   \n",
       "2   2024-05-31  4.7810  4.7840  4.6205  4.6020  4.095393   84255.0   \n",
       "3   2024-06-03  4.6610  4.6735  4.5710  4.6675  4.100434   74629.0   \n",
       "4   2024-06-04  4.6250  4.6920  4.5955  4.5370  4.106076   65807.0   \n",
       "..         ...     ...     ...     ...     ...       ...       ...   \n",
       "121 2024-11-19  4.0665  4.1355  4.0505  4.1420  4.250191   50803.0   \n",
       "122 2024-11-20  4.1240  4.1745  4.0885  4.1555  4.249115   50275.0   \n",
       "123 2024-11-21  4.1660  4.1790  4.1365  4.1250  4.248183   44315.0   \n",
       "124 2024-11-22  4.1530  4.1665  4.0970  4.0860  4.246958   45938.0   \n",
       "125 2024-11-25  4.1090  4.1195  4.0610  4.1000  4.245356   49185.0   \n",
       "\n",
       "     log_return_1  log_return_5  log_return_10  ...  timeframe_score_max  \\\n",
       "0       -0.013270     -0.067743      -0.073712  ...             0.999774   \n",
       "1       -0.028046     -0.039379      -0.047883  ...             0.999788   \n",
       "2       -0.012203      0.004177      -0.038736  ...             0.999786   \n",
       "3        0.014133     -0.026087      -0.023525  ...             0.999794   \n",
       "4       -0.028358     -0.026926      -0.048281  ...             0.999763   \n",
       "..            ...           ...            ...  ...                  ...   \n",
       "121      0.005326     -0.004866       0.019707  ...             0.999722   \n",
       "122      0.003254     -0.022709       0.014263  ...             0.999763   \n",
       "123     -0.007367     -0.003979       0.008864  ...             0.999761   \n",
       "124     -0.009500      0.003630       0.017185  ...             0.999776   \n",
       "125      0.003420      0.010832       0.045335  ...             0.999777   \n",
       "\n",
       "     timeframe_score_min  sentiment_neg_ratio  sentiment_neu_ratio  \\\n",
       "0               0.496353             0.410256             0.410256   \n",
       "1               0.927121             0.193548             0.483871   \n",
       "2               0.613561             0.270833             0.500000   \n",
       "3               0.575466             0.102041             0.408163   \n",
       "4               0.723079             0.277778             0.500000   \n",
       "..                   ...                  ...                  ...   \n",
       "121             0.544919             0.272727             0.500000   \n",
       "122             0.781507             0.062500             0.437500   \n",
       "123             0.638620             0.071429             0.785714   \n",
       "124             0.868944             0.241379             0.517241   \n",
       "125             0.695777             0.209677             0.483871   \n",
       "\n",
       "     sentiment_pos_ratio  time_past_ratio  time_present_ratio  \\\n",
       "0               0.179487         0.205128            0.230769   \n",
       "1               0.322581         0.225806            0.161290   \n",
       "2               0.229167         0.041667            0.145833   \n",
       "3               0.489796         0.183673            0.163265   \n",
       "4               0.222222         0.083333            0.222222   \n",
       "..                   ...              ...                 ...   \n",
       "121             0.227273         0.090909            0.181818   \n",
       "122             0.500000         0.062500            0.250000   \n",
       "123             0.142857         0.071429            0.214286   \n",
       "124             0.241379         0.103448            0.000000   \n",
       "125             0.306452         0.096774            0.258065   \n",
       "\n",
       "     time_future_ratio  item_id  time_idx  \n",
       "0             0.564103   copper      1646  \n",
       "1             0.612903   copper      1647  \n",
       "2             0.812500   copper      1648  \n",
       "3             0.653061   copper      1649  \n",
       "4             0.694444   copper      1650  \n",
       "..                 ...      ...       ...  \n",
       "121           0.727273   copper      1767  \n",
       "122           0.687500   copper      1768  \n",
       "123           0.714286   copper      1769  \n",
       "124           0.896552   copper      1770  \n",
       "125           0.645161   copper      1771  \n",
       "\n",
       "[126 rows x 39 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aab9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "tem_id = getattr(forecast_it, \"item_id\", None)\n",
    "print(tem_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e940eb72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
